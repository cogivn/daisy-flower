# Quick-Win Checklist

**SDLC Version**: 6.1.0
**Category**: Playbook
**Status**: Active
**License**: MIT

---

## Overview

A 5-day plan to get your first measurable win with SDLC-structured AI workflows. Total investment: 3-4 hours spread across one week.

This is the condensed version of the [Founder Playbook](founder-playbook.md). If you want the full 4-week program, start there. If you want one win this week, start here.

---

## Before You Start

You need:
- [ ] 3-4 hours available this week (distributed across days is fine)
- [ ] 1 AI tool account ready (ChatGPT, Claude, Copilot, Cursor — anything works)
- [ ] A spreadsheet or document for tracking
- [ ] 1 use case in mind (small, frequent, painful)

---

## Day 1 — Monday: Tool Audit (30 minutes)

### Morning (15 minutes)

- [ ] Open a spreadsheet
- [ ] List every AI tool your team uses right now
- [ ] For each tool, write its purpose in 1 sentence

### Afternoon (15 minutes)

- [ ] Map each tool to an SDLC stage:
  - 00-FOUNDATION: Research, ideation, problem validation
  - 01-PLANNING: Requirements, specs, user stories
  - 02-DESIGN: Architecture, system design, decisions
  - 03-INTEGRATE: API design, service contracts
  - 04-BUILD: Coding, testing, deployment
- [ ] Flag tools that don't map to any stage

**Done**: You now know what tools exist and which stages they serve.

---

## Day 2 — Tuesday: Owners and KPIs (45 minutes)

### Morning (30 minutes)

- [ ] For each tool, assign a specific owner (a person, not "the team")
- [ ] For each tool, define a KPI:
  - What does success look like?
  - Example: "Generate 3 PRDs per week in <1 hour each"
- [ ] Record the current baseline ("Currently: 2 PRDs/week, 2 hours each")

### Afternoon (15 minutes)

- [ ] Mark orphan tools:
  - No owner? Mark for review
  - No KPI? Mark for review
  - Not used in 2 weeks? Mark for removal
- [ ] Kill at least 1 tool today (the most obvious waste)

**Done**: Every tool has accountability or is marked for removal.

---

## Day 3 — Wednesday: Pick Your Battle (30 minutes)

### Choose 1 use case that meets ALL criteria:

- [ ] **Small**: Completable in 2 weeks or less
- [ ] **Frequent**: Team does this 3+ times per week
- [ ] **Painful**: Everyone knows this is inefficient
- [ ] **Measurable**: Can track time or quality
- [ ] **Repeatable**: Will do this again and again

### Write it down:

```
My use case: ___________________________________

Why this one:
- Small because: _______________________________
- Frequent because: ____________________________
- Painful because: _____________________________
- Measurable by: _______________________________
```

Good choices: "Idea to PRD draft", "Bug report to root cause", "Feature request to tech spec"

**Done**: You have 1 concrete target, not "improve everything."

---

## Day 4 — Thursday: Stage Mapping (1 hour)

### Map your use case through 5 SDLC stages:

```
00-FOUNDATION (5 min):
  Problem: _____________________________________
  Why it matters: ______________________________
  How AI can help: _____________________________

01-PLANNING (10 min):
  Desired outcome: _____________________________
  Success metric: ______________________________
  Target time: _________________________________

02-DESIGN (30 min):
  Step 1: [action] — [Human or AI?] — [output]
  Step 2: [action] — [Human or AI?] — [output]
  Step 3: [action] — [Human or AI?] — [output]
  Step 4: [action] — [Human or AI?] — [output]

  Quality Gate 1: After step ___, check ________
  Quality Gate 2: After step ___, check ________

03-INTEGRATE (5 min):
  Tools/APIs involved: _________________________
  Data that flows between steps: _______________

04-BUILD (10 min):
  Primary AI tool: _____________________________
  Test plan: Do it 3 times, track time & quality
```

### Choose your tools:

- [ ] Primary tool (does 70% of the work): _______________
- [ ] Secondary tool (validates or assists): _______________
- [ ] No more than 3 tools total

**Done**: A concrete, step-by-step plan exists for your use case.

---

## Day 5 — Friday: First Experiment (1 hour)

### Before starting:

- [ ] Note start time: ___________
- [ ] Have your stage map open
- [ ] Have your AI tool ready

### During:

- [ ] Follow the steps from your DESIGN section
- [ ] Note where you get stuck
- [ ] Note where AI helps vs. doesn't help
- [ ] Check quality gates — did you pass?

### After:

- [ ] End time: ___________
- [ ] Total time: ___________
- [ ] Quality self-rating (1-10): ___
- [ ] What worked: _________________
- [ ] What needs fixing: ____________

### Compare:

```
Usual way:    Time: _____ | Quality: _____
Structured:   Time: _____ | Quality: _____
Difference:   ___% faster/slower | ___% better/worse
```

**Done**: You have data. Even if the first run is slower, you've learned where the gains will come from.

---

## End of Week — Check Your Wins

### Must have (all required):

- [ ] Tool inventory exists with purpose and ownership
- [ ] At least 1 orphan tool killed
- [ ] 1 use case selected and scoped
- [ ] Stage map created with quality gates
- [ ] First experiment run completed
- [ ] Time and quality tracked (even if rough)

### Bonus (nice to have):

- [ ] Shared progress with a teammate
- [ ] Identified a 2nd use case for next week
- [ ] Calculated rough ROI

---

## Week 2: Iterate (If Momentum Is Good)

Run 4 more iterations of your use case:

| Day | Activity | Expected |
|-----|----------|----------|
| Monday | Run iteration 2, refine clunky steps | Back to baseline speed |
| Tuesday | Run iteration 3, tighten quality gates | Starting to feel natural |
| Wednesday | Run iteration 4, measure improvement | 10-20% faster |
| Thursday | Run iteration 5, final measurement | 30-50% faster |
| Friday | Document pattern (30 min), share with team | Reusable for next use case |

---

## Quick ROI Calculator

```
Your use case frequency: ___ times per week
Time saved per instance: ___ minutes
Team members who do this: ___ people

Weekly savings  = frequency x time saved x team size
Monthly savings = weekly x 4
Yearly savings  = monthly x 12

Example:
  Frequency: 3x/week
  Time saved: 30 min
  Team size: 3 people
  Weekly: 3 x 30 x 3 = 270 min = 4.5 hours
  Monthly: 18 hours
  Yearly: 216 hours = 5.4 work weeks
```

This is from **one** use case. Multiply by 3-5 patterns and the compound effect is significant.

---

## If You're Stuck

### "I don't have 3-4 hours this week"

Distribute: 15 min before standup, 20 min at lunch, 30 min in a focus block. The total is small — it just needs to be intentional.

### "My first run was slower, not faster"

Expected. The first iteration always is. The framework adds overhead *once* (creating the map). By iteration 3, you'll be at baseline. By iteration 5, you'll see gains. Stick with it for 5 tries before judging.

### "AI isn't helping"

Check: Are you giving AI enough context? Try: "Based on this problem statement, help me draft requirements with acceptance criteria." The stage map provides the context AI needs to be useful.

### "Team doesn't care"

Start solo. Prove it works for you. Share data after 2 weeks. "Demo beats pitch" — always.

---

## What's Next

After your first win:

1. **Go deeper**: Read the [Founder Playbook](founder-playbook.md) for the full 4-week program
2. **Scale up**: Apply the [Use Case Mapping Canvas](../04-templates/use-case-mapping-canvas.md) to 2-3 more use cases
3. **Understand why**: Read [Iceberg of Change](../01-core-concepts/iceberg-of-change.md) — you just fixed a *structure*, not an *event*

---

## See Also

- [LITE Quickstart](lite-quickstart.md) — project setup in 30 minutes
- [Founder Playbook](founder-playbook.md) — full 4-week adoption program
- [Crisis to Pattern](crisis-to-pattern.md) — turning failures into reusable patterns
- [Gate Checklist Template](../04-templates/gate-checklist-template.md) — formal gate checklists
